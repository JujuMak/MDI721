{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import unittest\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "# options d'affichage\n",
    "pd.set_option(\"display.min_rows\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL_PAGE2 = \"https://kim.fspot.org/cours/page2.html\"\n",
    "URL_PAGE3 = \"https://kim.fspot.org/cours/page3.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure we are allowed to scrap the page\n",
    "requests.get(URL_PAGE2).status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Ecrire une fonction get_prices_from_url() qui extrait des informations à partir des 2 pages ci-dessus.\n",
    "# Exemple get_prices_from_url(URL_PAGE2) doit retourner :\n",
    "# {'Personal': {'price': '$5', 'storage': '1GB', 'databases': 1},\n",
    "#  'Small Business': {'price': '$25', 'storage': '10GB', 'databases': 5},\n",
    "#  'Enterprise': {'price': '$45', 'storage': '100GB', 'databases': 25}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the content of web page\n",
    "content = requests.get(URL_PAGE2).content.decode('utf-8')\n",
    "\n",
    "# Create a BeautifulSoup object of it\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "## After first insight into soup, I can see that all the interesting data is\n",
    "# located into div class named 'pricing-tables pure-g'\n",
    "## Trying to break down the problem by isolating the area of interest. \n",
    "## In this exercise, this is not too much useful as the site is not very big. \n",
    "\n",
    "soup = soup.find('div', class_ = 'pricing-tables pure-g')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : Isolate data one by one in one single offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolate offer type\n",
    "offer_type = soup.find('h2').text\n",
    "# typr offre = soup_url2. trouve les lignes <h2> puis en extrait le text correspondant\n",
    "offer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Isolate price\n",
    "\n",
    "offer_price = soup.find('span', class_ = 'pricing-table-price').text.split()[0]\n",
    "#  prix service = soup.find(lignes <span> ayant la classe 'pricing-table-price'). on sort le texte \n",
    "# et on le splitte. On prend ensuite le premier élément [0] qui correspond à $5\n",
    "\n",
    "offer_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Isolate storage and database size as they are both under \"li\"\n",
    "# These infos are under <ul class=\"pricing-table-list\">\n",
    "#                         <li>\n",
    "\n",
    "offer_storage = soup.find('ul', class_=\"pricing-table-list\").find_all('li')[3].text.split()[0]\n",
    "# storage= find in ul pricing-table-list --> find all 'li' as they contain relevant data.\n",
    "# the storage is in position [3]. We then want the text, split it and take 1st item as \n",
    "# it is the size that we are looking for\n",
    "\n",
    "offer_database = soup.find('ul', class_=\"pricing-table-list\").find_all('li')[4].text.split()[0]\n",
    "# same as storage. But in this case, it is in element index 4 of the find(ul, class).find_all(li)\n",
    "\n",
    "print(\"Storage found : \", offer_storage)\n",
    "print(\"Database found : \", offer_database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Now that we have successfully extracted elements we wanted for one single offer, we want to make a for loop to catch same info from other offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Since we found the information under class_=\"pricing-table\", we need to catch all\n",
    "# the similar pricing-table classes using the find_all function\n",
    "pricing_table = soup.find_all(class_=\"pricing-table\")\n",
    "\n",
    "\n",
    "output = {}\n",
    "\n",
    "for offer in pricing_table:  # for offer in personal/smallbizness/entreprise/etc...\n",
    "    offer_type = offer.find('h2').text\n",
    "    offer_price = offer.find('span', class_ = 'pricing-table-price').text.split()[0]\n",
    "    offer_storage = offer.find('ul', class_=\"pricing-table-list\").find_all('li')[3].text.split()[0]\n",
    "    offer_database = int(offer.find('ul', class_=\"pricing-table-list\").find_all('li')[4].text.split()[0])\n",
    "        \n",
    "    output[offer_type] = {\n",
    "        'price': offer_price,\n",
    "        'storage': offer_storage,\n",
    "        'databases': offer_database,\n",
    "    }\n",
    "    \n",
    "    \n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Put all these operations in a def function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices_from_url(url):\n",
    "    content = requests.get(url).content.decode('utf-8')\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    soup = soup.find('div', class_ = 'pricing-tables pure-g')\n",
    "    \n",
    "    pricing_table = soup.find_all(class_=\"pricing-table\")\n",
    "\n",
    "\n",
    "    prices = {}\n",
    "\n",
    "    for offer in pricing_table:  # for offer in personal/smallbizness/entreprise/etc...\n",
    "        offer_type = offer.find('h2').text\n",
    "        offer_price = offer.find('span', class_ = 'pricing-table-price').text.split()[0]\n",
    "        offer_storage = offer.find('ul', class_=\"pricing-table-list\").find_all('li')[3].text.split()[0]\n",
    "\n",
    "        offer_database = int(offer.find('ul', class_=\"pricing-table-list\").find_all('li')[4].text.split()[0])\n",
    "\n",
    "        prices[offer_type] = {\n",
    "            'price': offer_price,\n",
    "            'storage': offer_storage,\n",
    "            'databases': offer_database,\n",
    "        }\n",
    "\n",
    "    \n",
    "    return prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : test it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_prices_from_url(URL_PAGE3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXO 2 \n",
    "### Ecrire une fonction qui extrait des informations sur une bière de beowulf\n",
    "### Exemple URL: https://www.beerwulf.com/fr-fr/p/bieres/brouwerij-t-verzet-super-noah.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: retrieve data, select what we want of it and print it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URL= 'https://www.beerwulf.com/fr-fr/p/bieres/brouwerij-t-verzet-super-noah.33'\n",
    "# start by getting info from the url \n",
    "content = requests.get(URL).content.decode('utf-8')\n",
    "\n",
    "# Create a BeautifulSoup object of it\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# focus on the interesting part of data\n",
    "soup = soup.find('div', class_ = 'product-detail-info-row')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Isolate requested values for function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out name\n",
    "name = soup.find('h1').text\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out note\n",
    "note = int(soup.find(class_=\"stars\").attrs['data-percent'])\n",
    "note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out price\n",
    "price = float(soup.find('span',class_=\"price\").text.split()[0].replace(\",\",\".\"))\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out volume\n",
    "# volume = float(soup.find('div',class_=\"product-subtext\").find('span').text.split()[5].replace(\"%\",\"\").replace(\",\",\".\"))\n",
    "volume = float(soup.find('div',class_=\"product-subtext\").find('span').text.split()[-2])\n",
    "\n",
    "volume, type(volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: pieces of code are ready to be put in the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the full fonction containing data reading and values identification\n",
    "\n",
    "def extract_beer_infos(url):\n",
    "\n",
    "    content = requests.get(url).content.decode('utf-8')\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    soup = soup.find('div', class_ = 'product-detail-info-row')\n",
    "    \n",
    "    name = soup.find('h1').text\n",
    "    note = int(soup.find(class_=\"stars\").attrs['data-percent'].replace('\\n',''))\n",
    "    price = float(soup.find('span',class_=\"price\").text.split()[0].replace(\",\",\".\").replace('\\n',''))\n",
    "    volume = float(soup.find('div',class_=\"product-subtext\").find('span').text.split()[-2].replace('\\n',''))\n",
    "    \n",
    "\n",
    "#     infos = {\n",
    "#         'name': name, \n",
    "#         'note': note,\n",
    "#         'price': price,\n",
    "#         'volume': volume,\n",
    "    infos = {'name': name, 'note': note,'price': price,'volume': volume}\n",
    "        \n",
    "    return infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Test on a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test on the page to check that it scraps data correctly\n",
    "\n",
    "extract_beer_infos('https://beerwulf.com/fr-fr/p/bieres/engelzell-trappisten-weibe-bottle-.33')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3) Ecrire une fonction qui prend l'argument \"url\" retourne les informations sur une liste de bière via l'API de beowulf.\n",
    "# Cette fonction doit retourner la liste des informations obtenues par la fonction extract_beer_infos() définie ci-dessus.\n",
    "# Chercher comment optimiser cette fonction en utilisant multiprocessing.Pool pour paralléliser les accès web.\n",
    "#\n",
    "# Exemple de retour :\n",
    "# [{'name': 'Engelszell Benno', 'note': 70, 'price': 4.29, 'volume': 33}\n",
    "#  {'name': 'Engelszell Trappisten Weiße', 'note': 70, 'price': 3.39, 'volume': 33}\n",
    "#  {'name': 'Engelszell Gregorius', 'note': 70, 'price': 4.49, 'volume': 33}\n",
    "#  {'name': 'Bevog Rudeen Black IPA', 'note': 80, 'price': 4.49, 'volume': 33}\n",
    "#  {'name': 'Bevog Tak Pale Ale', 'note': 70, 'price': 2.79, 'volume': 33}\n",
    "#  {'name': 'Brew Age Affenkönig', 'note': 70, 'price': 3.49, 'volume': 33}\n",
    "#  {'name': 'Stiegl Goldbraü', 'note': 70, 'price': 2.49, 'volume': 33}\n",
    "#  {'name': 'Stiegl Columbus 1492', 'note': 70, 'price': 2.49, 'volume': 33}\n",
    "#  {'name': 'Brew Age Hopfenauflauf', 'note': 70, 'price': 2.99, 'volume': 33}]\n",
    "\n",
    "# get the content of web page\n",
    "content = requests.get(URL_PAGE2).content.decode('utf-8')\n",
    "\n",
    "# Create a BeautifulSoup object of it\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "# Cette URL retourne un JSON avec une liste de bières\n",
    "URL_BEERLIST_AUTRICHE = \"https://www.beerwulf.com/fr-FR/api/search/searchProducts?country=Autriche&container=Bouteille\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to load data from json ? \n",
    "content = requests.get(URL_BEERLIST_AUTRICHE)\n",
    "content = content.json()\n",
    "content,type(content)\n",
    "# turns out that content is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to isolate beer page\n",
    "content['items'][1]['contentReference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collecter les pages de bières à partir du JSON\n",
    "beer_pages = []\n",
    "\n",
    "for i in content['items']:\n",
    "    beer_pages.append(\"https://beerwulf.com\" + i['contentReference'])\n",
    "\n",
    "beer_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "type(os.cpu_count())\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "type(os.cpu_count())\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "## CELLE CI MARCHE EN SEQUENTIEL !!!\n",
    "\n",
    "def extract_beer_list_infos(url):\n",
    "    # ouvrir le json dans python\n",
    "    content = requests.get(url).json()\n",
    "    \n",
    "    # Collecter les pages de bières à partir du JSON\n",
    "    beer_pages = []\n",
    "    \n",
    "    for i in content['items']:\n",
    "        beer_pages.append(\"https://beerwulf.com\" + i['contentReference'])\n",
    "\n",
    "    \n",
    "    beers = []\n",
    "    \n",
    "    # Sequential version (slow):\n",
    "    for page in beer_pages:\n",
    "         beers.append(extract_beer_infos(page))\n",
    "\n",
    "#     #Parallel version (faster):\n",
    "#     from multiprocessing import Pool\n",
    "#     import os\n",
    "#     p = Pool(processes=os.cpu_count())   #  processes est le nombre de processus workers à utiliser. \n",
    "#     # Si processes est None, le nombre renvoyé par os.cpu_count() est utilisé.\n",
    "#     beers = p.imap(extract_beer_infos, beer_pages)\n",
    "#     # on utilise le process créé et on passe la fonction extract_beer_list_info sur tous les éléments de beer_pages\n",
    "#     p.close()\n",
    "#     p.join()\n",
    "#     return beers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "extract_beer_list_infos(URL_BEERLIST_AUTRICHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Lesson3Tests(unittest.TestCase):\n",
    "    def test_01_get_prices_from_url_page2(self):\n",
    "        prices = get_prices_from_url(URL_PAGE2)\n",
    "        # We should have found 3 products:\n",
    "        self.assertIsInstance(prices, dict)\n",
    "        self.assertEqual(len(prices), 3)\n",
    "        self.assertIn('Personal', prices)\n",
    "        self.assertIn('Small Business', prices)\n",
    "        self.assertIn('Enterprise', prices)\n",
    "\n",
    "        personal = prices['Personal']\n",
    "        self.assertIn('price', personal)\n",
    "        self.assertIn('storage', personal)\n",
    "        self.assertIn('databases', personal)\n",
    "        self.assertEqual(personal['price'], '$5')\n",
    "        self.assertEqual(personal['storage'], '1GB')\n",
    "        self.assertEqual(personal['databases'], 1)\n",
    "\n",
    "    def test_02_get_prices_from_url_page3(self):\n",
    "        prices = get_prices_from_url(URL_PAGE3)\n",
    "        self.assertIsInstance(prices, dict)\n",
    "        self.assertEqual(len(prices), 4)\n",
    "        self.assertEqual(\n",
    "            prices['Privilege'],\n",
    "            {'databases': 100, 'price': '$99', 'storage': '1TB'}\n",
    "        )\n",
    "\n",
    "    def test_03_extract_beer_list_infos(self):\n",
    "        infos = extract_beer_list_infos(URL_BEERLIST_AUTRICHE)\n",
    "        # >Il y a 9 bières autrichiennes :\n",
    "        self.assertIsInstance(infos, list)\n",
    "        self.assertEqual(len(infos), 9)\n",
    "        # toutes ont 33cl :\n",
    "        for beer in infos:\n",
    "            self.assertEqual(beer['volume'], 33)\n",
    "\n",
    "\n",
    "def run_tests():\n",
    "    test_suite = unittest.makeSuite(Lesson3Tests)\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    runner.run(test_suite)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_tests()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
